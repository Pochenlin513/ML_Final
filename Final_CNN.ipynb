{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('E:/NTHUcourses/三上/機器學習/final/dataset/train.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/discussion/41806#latest-666617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pixel = df[1].values\n",
    "label = df[0].values\n",
    "X = pixel[1:]\n",
    "y = label[1:]\n",
    "for i in range(0, len(X)):\n",
    "    X[i] = X[i].split(\" \")\n",
    "    y[i] = int(y[i])\n",
    "    for j in range(0, len(X[i])):\n",
    "        X[i][j] = float(X[i][j])/255.0\n",
    "for i in range(0, len(X)):\n",
    "    X[i]=np.array(X[i])\n",
    "X = np.vstack(X)\n",
    "y = np.vstack(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將Label轉成onehot的形式，並且在輸入的部分用reshape將X轉成(28709, 48, 48, 1)的四維陣列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "y_onehot = label_binarize(y, [0, 1, 2, 3, 4, 5, 6])\n",
    "X=X.reshape(28709, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切出30%的資料做為測試用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y_onehot,\n",
    "                    test_size = 0.3,\n",
    "                    random_state = 0,\n",
    "                    stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用keras來建構我的神經網路\n",
    "\n",
    "首先是connvolution layer，因為圖片是48X48的大小，並沒有太大，所以filter的大小選擇用3X3，並用same padding保持圖片大小\n",
    "接著加一層pooling layer，採用2X2的大小將圖片縮減為24X24\n",
    "\n",
    "再重複兩次上面的過程，並加一層dropout layer降低overfit的效應\n",
    "\n",
    "接著加一層hidden layer，因為最後的output是7種class，經過嘗試後選擇用7X16=224個神經元作為hidden layer的大小\n",
    "\n",
    "最後是7個神經元的output layer\n",
    "(因為features的值都是介於0-1之間，所以activation都是用relu就好)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 20,\n",
    "                 kernel_size = (3,3),\n",
    "                 padding = 'same',\n",
    "                 input_shape = (48,48,1),\n",
    "                 activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2),))\n",
    "model.add(Conv2D(filters = 20,\n",
    "                 kernel_size = (3,3),\n",
    "                 padding = 'same',\n",
    "                 activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(filters = 20,\n",
    "                 kernel_size = (3,3),\n",
    "                 padding = 'same',\n",
    "                 activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 224,\n",
    "                activation = 'relu'))\n",
    "model.add(Dense(units = 7, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試了幾次之後發現這次資料收斂很快，如果batch size太大的話雖然每個epoch時間變短，但需要用很多個epoch才能達到較高的準確度，並且會有overfit的現象。所以最後挑選batch size為64，並切出20%的資料作驗證\n",
    "\n",
    "其實過了10個epoch之後也出現了overfit的狀況，不過還是有稍微提升了點準確度。最後的結果為52.67%的準確度，雖然並沒有很高，但參考網站上的排行榜也已經高於一半的參賽者。\n",
    "\n",
    "這次的準確度不足，我猜想可能是圖片的大小並不大，只有48X48的尺寸，可能在辨識情緒上有點不足；也可能是我在神經網路的設計上仍有缺陷，或是應該使用其他模型去完成分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16076 samples, validate on 4020 samples\n",
      "Epoch 1/15\n",
      " - 46s - loss: 1.7594 - acc: 0.2822 - val_loss: 1.6550 - val_acc: 0.3351\n",
      "Epoch 2/15\n",
      " - 48s - loss: 1.6014 - acc: 0.3778 - val_loss: 1.5274 - val_acc: 0.4127\n",
      "Epoch 3/15\n",
      " - 46s - loss: 1.5099 - acc: 0.4183 - val_loss: 1.4572 - val_acc: 0.4430\n",
      "Epoch 4/15\n",
      " - 45s - loss: 1.4524 - acc: 0.4439 - val_loss: 1.4301 - val_acc: 0.4597\n",
      "Epoch 5/15\n",
      " - 38s - loss: 1.3980 - acc: 0.4656 - val_loss: 1.3686 - val_acc: 0.4799\n",
      "Epoch 6/15\n",
      " - 34s - loss: 1.3570 - acc: 0.4796 - val_loss: 1.4009 - val_acc: 0.4600\n",
      "Epoch 7/15\n",
      " - 37s - loss: 1.3184 - acc: 0.4974 - val_loss: 1.3295 - val_acc: 0.4863\n",
      "Epoch 8/15\n",
      " - 37s - loss: 1.2741 - acc: 0.5167 - val_loss: 1.3045 - val_acc: 0.5047\n",
      "Epoch 9/15\n",
      " - 46s - loss: 1.2407 - acc: 0.5282 - val_loss: 1.3122 - val_acc: 0.5042\n",
      "Epoch 10/15\n",
      " - 39s - loss: 1.2036 - acc: 0.5445 - val_loss: 1.2855 - val_acc: 0.5172\n",
      "Epoch 11/15\n",
      " - 36s - loss: 1.1665 - acc: 0.5624 - val_loss: 1.2837 - val_acc: 0.5047\n",
      "Epoch 12/15\n",
      " - 34s - loss: 1.1296 - acc: 0.5750 - val_loss: 1.2777 - val_acc: 0.5117\n",
      "Epoch 13/15\n",
      " - 35s - loss: 1.0871 - acc: 0.5931 - val_loss: 1.2800 - val_acc: 0.5082\n",
      "Epoch 14/15\n",
      " - 34s - loss: 1.0516 - acc: 0.6069 - val_loss: 1.2814 - val_acc: 0.5206\n",
      "Epoch 15/15\n",
      " - 37s - loss: 1.0128 - acc: 0.6222 - val_loss: 1.2862 - val_acc: 0.5144\n",
      "8613/8613 [==============================] - 5s 619us/step\n",
      "Accuracy: 0.526762\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x=X_train, y=y_train,\n",
    "                          validation_split = 0.2,\n",
    "                          epochs = 15, batch_size = 64, verbose = 2)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: %f\" %scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
